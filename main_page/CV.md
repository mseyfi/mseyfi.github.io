<div style="background-color: #f3f3f3; color: #512; font-weight: 500; padding: 20px; margin: 20px 0; border-radius: 8px; border: 1px solid #ccc;">
  <h2>Preface:</h2>
  <p>
This page is dedicated to my Computer Vision explorations ðŸš€.


Iâ€™ve discovered that I grasp concepts more effectively when I understand a simple code example associated with them. Therefore, in this blog, I explore new concepts through coding!|

I try to use simple scenarios and of course, I never use ChatGPTðŸ¤¥.
</p>
</div>

<p>


</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>

[<img src="../images/LinkedIn_logo_initials.png"  width="40" height="40">](https://www.linkedin.com/in/mehdi-seyfi-38189220/)   [<img src="../images/googlescholar.png"  width="40" height="40">](https://scholar.google.ca/citations?user=6l0PmOEAAAAJ&hl=en) [<img src="../images/github.png"  width="40" height="40">](https://github.com/mseyfi)



[![DETR](https://img.shields.io/badge/DETR-Detection_Transformer-blue?style=for-the-badge&logo=github)](../posts/DETR)

<div style="background-color: #f0f8ff; color: #555;font-weight: 485; padding: 20px; margin: 20px 0; border-radius: 8px; border: 1px solid #ccc;">
The Detection Transformer (DETR) is a novel approach to object detection that leverages Transformers, which were originally designed for sequence-to-sequence tasks like machine translation. Introduced by Carion et al. in 2020, DETR simplifies the object detection pipeline by eliminating the need for hand-crafted components like anchor generation and non-maximum suppression (NMS).
 <p></p>
_Last updated: {{ site.time | date: "%B %d, %Y" }}_
</div>

## [![VIT](https://img.shields.io/badge/VIT-Vision_Transformers-blue?style=for-the-badge&logo=github)](../posts/VIT)
<div style="background-color: #f0f8ff; color: #555;font-weight: 485; padding: 20px; margin: 20px 0; border-radius: 8px; border: 1px solid #ccc;">
Vision Transformers (ViTs) apply the Transformer architecture, originally designed for natural language processing (NLP), to computer vision tasks like image classification. ViTs treat an image as a sequence of patches (akin to words in a sentence) and process them using Transformer encoders. <p></p>
_Last updated: {{ site.time | date: "%B %d, %Y" }}_
</div>

## [![CGANS](https://img.shields.io/badge/CGANs-Conditional_GAN-blue?style=for-the-badge&logo=github)](../posts/ConditionalGan)
<div style="background-color: #f0f8ff; color: #555;font-weight: 485; padding: 20px; margin: 20px 0; border-radius: 8px; border: 1px solid #ccc;">
Python implementation of a Conditional Generative Adversarial Network (cGAN) using PyTorch.
 <p></p>
_Last updated: {{ site.time | date: "%B %d, %Y" }}_
</div>

## [![Distillation](https://img.shields.io/badge/Distillation-grey?style=for-the-badge&logo=github)](../posts/Distillation)
<div style="background-color: #f0f8ff; color: #555;font-weight: 485; padding: 20px; margin: 20px 0; border-radius: 8px; border: 1px solid #ccc;">
Generalization issue with Distillation
 <p></p>
_Last updated: {{ site.time | date: "%B %d, %Y" }}_
</div>




